{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para leer datos de Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path de la carpeta donde tenemos los datos\n",
    "folder = \"/content/drive/MyDrive/Colab Notebooks/BD NOVIEMBRE/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carga de datos\n",
    "df = pd.read_csv(folder + \"Canciones_Spotify.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos = df.columns.tolist()\n",
    "titulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = df[[\"danceability\", \"energy\", \"valence\", \"loudness\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = selected_features\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualización de la distribución de 'target'\n",
    "sns.countplot(data=df, x='target')\n",
    "plt.title(\"Distribución de 'target'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de Modelos de Aprendizaje Automático\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Crear modelos\n",
    "knn_model = KNeighborsClassifier()\n",
    "svm_model = SVC()\n",
    "dt_model = DecisionTreeClassifier()\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Entrenar los modelos con los datos de entrenamiento\n",
    "knn_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Validación cruzada k-fold\n",
    "knn_scores = cross_val_score(knn_model, X_train, y_train, cv=5)\n",
    "svm_scores = cross_val_score(svm_model, X_train, y_train, cv=5)\n",
    "dt_scores = cross_val_score(dt_model, X_train, y_train, cv=5)\n",
    "nb_scores = cross_val_score(nb_model, X_train, y_train, cv=5)\n",
    "\n",
    "# Muestra los puntajes promedio de validación cruzada para cada modelo\n",
    "print(\"K-Nearest Neighbors (KNN) - Puntaje promedio:\", knn_scores.mean())\n",
    "print(\"Support Vector Machines (SVM) - Puntaje promedio:\", svm_scores.mean())\n",
    "print(\"Árbol de decisión - Puntaje promedio:\", dt_scores.mean())\n",
    "print(\"Naive Bayes - Puntaje promedio:\", nb_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenar el modelo KNN con los datos de entrenamiento\n",
    "knn_model.fit(X_train, y_train) # se puede sacar ya que esta mas arriba\n",
    "\n",
    "# Realizar predicciones en los datos de prueba\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Matriz de confusión para el modelo KNN\n",
    "cm = confusion_matrix(y_test, y_pred_knn)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title(\"Matriz de Confusión - KNN\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Verdadero\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste de Hiperparámetros para ver si podemos mejorar su rendimiento\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir los hiperparámetros que deseas ajustar para cada modelo\n",
    "knn_param_grid = {'n_neighbors': [3, 5, 7, 9]}\n",
    "svm_param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "dt_param_grid = {'max_depth': [None, 5, 10, 15]}\n",
    "nb_param_grid = {}  # No hay hiperparámetros para ajustar en Naive Bayes\n",
    "\n",
    "# Crear objetos GridSearchCV para cada modelo\n",
    "knn_grid = GridSearchCV(knn_model, knn_param_grid, cv=5)\n",
    "svm_grid = GridSearchCV(svm_model, svm_param_grid, cv=5)\n",
    "dt_grid = GridSearchCV(dt_model, dt_param_grid, cv=5)\n",
    "nb_grid = nb_model  # No se ajustan hiperparámetros en Naive Bayes\n",
    "\n",
    "# Realizar el ajuste de hiperparámetros\n",
    "knn_grid.fit(X_train, y_train)\n",
    "svm_grid.fit(X_train, y_train)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros\n",
    "best_knn_params = knn_grid.best_params_\n",
    "best_svm_params = svm_grid.best_params_\n",
    "best_dt_params = dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Crear un modelo de votación mayoritaria\n",
    "voting_model = VotingClassifier(estimators=[\n",
    "    ('KNN', knn_model),\n",
    "    ('SVM', svm_model),\n",
    "    ('DecisionTree', dt_model),\n",
    "    ('NaiveBayes', nb_model)\n",
    "], voting='hard')  # 'hard' significa votación por mayoría\n",
    "\n",
    "# Entrenar el modelo de votación con los datos de entrenamiento\n",
    "voting_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Predicciones del modelo de votación\n",
    "y_pred_voting = voting_model.predict(X_test)\n",
    "\n",
    "# Predicciones de cada modelo individual\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Función para imprimir métricas\n",
    "def print_metrics(y_true, y_pred, model_name):\n",
    "    print(f\"Modelo: {model_name}\")\n",
    "    print(\"Matriz de Confusión:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"Precisión:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1-Score:\", f1_score(y_true, y_pred))\n",
    "    print(\"Exactitud (Accuracy):\", accuracy_score(y_true, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Imprimir métricas para el modelo de votación\n",
    "print_metrics(y_test, y_pred_voting, \"Modelo de Votación\")\n",
    "\n",
    "# Imprimir métricas para cada modelo individual\n",
    "print_metrics(y_test, y_pred_knn, \"K-Nearest Neighbors (KNN)\")\n",
    "print_metrics(y_test, y_pred_svm, \"Support Vector Machines (SVM)\")\n",
    "print_metrics(y_test, y_pred_dt, \"Árbol de decisión\")\n",
    "print_metrics(y_test, y_pred_nb, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predicciones del modelo de votación\n",
    "y_pred_voting = voting_model.predict(X_test)\n",
    "\n",
    "# Predicciones de cada modelo individual\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "def Matriz_confusion_grafica(y_true, y_pred, model_name):\n",
    "    # Calcular la matriz de confusión\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Visualizar la matriz de confusión con Seaborn\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Matriz de Confusión - {model_name}\")\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.ylabel(\"Verdadero\")\n",
    "    plt.show()\n",
    "\n",
    "Matriz_confusion_grafica(y_test, y_pred_voting, \"Modelo de Votación\")\n",
    "Matriz_confusion_grafica(y_test, y_pred_knn, \"K-Nearest Neighbors (KNN)\")\n",
    "Matriz_confusion_grafica(y_test, y_pred_svm, \"Support Vector Machines (SVM)\")\n",
    "Matriz_confusion_grafica(y_test, y_pred_dt, \"Árbol de decisión\")\n",
    "Matriz_confusion_grafica(y_test, y_pred_nb, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calcular precisión, recall y F1-score para KNN\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "\n",
    "precision_nb = precision_score(y_test, y_pred_nb)\n",
    "recall_nb = recall_score(y_test, y_pred_nb)\n",
    "f1_nb = f1_score(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Crear un DataFrame con todas las métricas para todos los modelos\n",
    "all_metrics = pd.DataFrame({\n",
    "    'Modelo': ['KNN', 'SVM', 'Árbol de Decisión', 'Naive Bayes'],\n",
    "    'Precisión': [precision_knn, precision_svm, precision_dt, precision_nb],\n",
    "    'Recall': [recall_knn, recall_svm, recall_dt, recall_nb],\n",
    "    'F1-Score': [f1_knn, f1_svm, f1_dt, f1_nb]\n",
    "})\n",
    "\n",
    "# Reorganizar los datos para el lineplot\n",
    "all_metrics = all_metrics.melt(id_vars='Modelo', var_name='Métrica', value_name='Valor')\n",
    "\n",
    "# Visualización de todas las métricas en un lineplot\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='Métrica', y='Valor', hue='Modelo', data=all_metrics, palette='husl', marker='o')\n",
    "plt.title('Métricas para todos los modelos')\n",
    "plt.ylabel('Valor')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
